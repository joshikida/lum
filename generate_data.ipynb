{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "272f640f",
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 0.64 # km\n",
    "SUBSET_SIZE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acc59280",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'geopandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\n\u001b[1;32m      4\u001b[0m matplotlib\u001b[38;5;241m.\u001b[39mrc(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfigure\u001b[39m\u001b[38;5;124m'\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m10\u001b[39m))\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgeopandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgpd\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mshapely\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeometry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Point\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshapely\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeometry\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'geopandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib\n",
    "matplotlib.rc('figure', figsize=(10, 10))\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import shapely.geometry\n",
    "import contextily as ctx\n",
    "from shapely import wkt\n",
    "from shapely import Polygon\n",
    "import mercantile\n",
    "import osmnx as ox\n",
    "import numpy as np\n",
    "\n",
    "import pyproj\n",
    "from pyproj import Transformer\n",
    "import rasterio\n",
    "\n",
    "\n",
    "import dask.dataframe as dd\n",
    "import math\n",
    "\n",
    "import time\n",
    "\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de3f3731",
   "metadata": {},
   "outputs": [],
   "source": [
    "def utm_to_latlon(easting, northing, zone_number=10, zone_letter=\"N\"):\n",
    "    \"\"\"\n",
    "    Convert UTM coordinates to Latitude and Longitude.\n",
    "\n",
    "    Parameters:\n",
    "        easting (float): The easting coordinate (meters).\n",
    "        northing (float): The northing coordinate (meters).\n",
    "        zone_number (int): The UTM zone number.\n",
    "        zone_letter (str): The UTM zone letter.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (latitude, longitude)\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    utm_proj = pyproj.Proj(\n",
    "        proj='utm',\n",
    "        zone=zone_number,\n",
    "        ellps='WGS84',\n",
    "        south=(zone_letter.upper() < 'N')\n",
    "    )\n",
    "    latlon_proj = pyproj.Proj(proj='latlong', datum='WGS84')\n",
    "    \"\"\"\n",
    "    \n",
    "    transformer = Transformer.from_crs(\"EPSG:32610\", \"EPSG:4326\") # no. 1 is CRS for UTM N 10 - CHANGE, no. 2 is std\n",
    "    #longitude, latitude = pyproj.transform(utm_proj, latlon_proj, easting, northing)\n",
    "    return transformer.transform(easting, northing)\n",
    "    \n",
    "    #return latitude, longitude\n",
    "\n",
    "def extract_subgrids_with_bounds_utm(raster_filepath, origin, pixel_size_m=10, subgrid_size=64, null_value=-3.4e+38, tol=1e-6, zone_number=33, zone_letter='T'):\n",
    "    with rasterio.open(raster_filepath) as src:\n",
    "        raster = src.read(1)\n",
    "    \n",
    "    subgrids_with_bounds = []\n",
    "    rows, cols = raster.shape\n",
    "    \n",
    "    for i in range(0, rows, subgrid_size):\n",
    "        for j in range(0, cols, subgrid_size):\n",
    "            subgrid = raster[i:i+subgrid_size, j:j+subgrid_size]\n",
    "            \n",
    "            contains_null = np.any(np.isclose(subgrid, null_value, atol=tol))\n",
    "            \n",
    "            if not contains_null:\n",
    "                # Calculate bounds in UTM\n",
    "                min_easting = origin[0] + j * pixel_size_m\n",
    "                max_easting = min_easting + subgrid_size * pixel_size_m\n",
    "                max_northing = origin[1] - i * pixel_size_m  # Assuming origin is top-left\n",
    "                min_northing = max_northing - subgrid_size * pixel_size_m\n",
    "                \n",
    "                # Convert UTM bounds to lat/lon for polygon creation\n",
    "                min_lat, min_lon = utm_to_latlon(min_easting, min_northing, zone_number, zone_letter)\n",
    "                max_lat, max_lon = utm_to_latlon(max_easting, max_northing, zone_number, zone_letter)\n",
    "                \n",
    "                # Create a polygon\n",
    "                polygon = Polygon([\n",
    "                    (min_lon, min_lat),\n",
    "                    (min_lon, max_lat),\n",
    "                    (max_lon, max_lat),\n",
    "                    (max_lon, min_lat)\n",
    "                ])\n",
    "                \n",
    "                subgrids_with_bounds.append((subgrid, polygon))\n",
    "    \n",
    "    return subgrids_with_bounds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30e6c55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bound_dots (poly): return [Point(vtx) for vtx in list(coord_window(34.0522,-118.2437).exterior.coords)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fad94eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_plot(coords, clr=\"red\", ax=None):\n",
    "    \"\"\"plot coords on a map\"\"\"\n",
    "\n",
    "    try:\n",
    "        gdf = gpd.GeoDataFrame(geometry=coords, crs=\"EPSG:4326\").to_crs(epsg=3857)\n",
    "    except:\n",
    "        gdf = gpd.GeoDataFrame(geometry=coords['geometry'], crs=\"EPSG:4326\").to_crs(epsg=3857)\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(30, 30))\n",
    "    gdf.plot(ax=ax, facecolor='none', edgecolor=clr)\n",
    "    ax.patch.set_edgecolor(clr)\n",
    "    ax.patch.set_linewidth(1)\n",
    "    ctx.add_basemap(ax, zoom=\"auto\", source=ctx.providers.OpenStreetMap.Mapnik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61c70f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_gs (ax,gs,text,round_=False,grid=False,fontsize=10):\n",
    "    if grid:\n",
    "        geoms = gpd.GeoSeries(gs.flatten())\n",
    "        geoms.crs = \"EPSG:4326\"\n",
    "        geoms = geoms.to_crs(epsg=3857)\n",
    "\n",
    "    else:\n",
    "        geoms = gs\n",
    "    for i, geom in enumerate(geoms):\n",
    "        x, y = geom.centroid.x, geom.centroid.y\n",
    "        t = str(text[i]).split(\".\")[0] if round_ else text[i]\n",
    "        ax.annotate(t, xy=(x, y), ha='center', va='center', color='red',fontsize=fontsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77e4888b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_map_plot(colors, *args):\n",
    "    \"\"\"plot multiple points/polygons etc on map\"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    if len(colors) < len(args): colors *= math.ceil(len(args)/len(colors))\n",
    "    for i, arg in enumerate(tqdm(args)): \n",
    "        map_plot(arg, ax=ax, clr=colors[i])\n",
    "\n",
    "    ax.patch.set_edgecolor('yellow')  \n",
    "    ax.patch.set_linewidth(1)  \n",
    "    ctx.add_basemap(ax, zoom=\"auto\", source=ctx.providers.OpenStreetMap.Mapnik)\n",
    "    \n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c3c06f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sindex_search (aoi, to_search):\n",
    "    sindex = to_search['geometry'].sindex\n",
    "    bbox = aoi.bounds\n",
    "    possible_matches_index = list(sindex.intersection(bbox))\n",
    "    possible_matches = to_search.iloc[possible_matches_index]\n",
    "    possible_matches.set_geometry(\"geometry\")\n",
    "    precise_matches = possible_matches[possible_matches['geometry'].intersects(aoi)]\n",
    "    return precise_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8086f6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ftp_links = pd.read_csv(\"https://minedbuildings.blob.core.windows.net/global-buildings/dataset-links.csv\")\n",
    "def get_footprints (quad_keys,aoi_shape):\n",
    "    \"\"\"return all building footprint data in aoi\"\"\"\n",
    "    ret = gpd.GeoDataFrame([])\n",
    "    for qkey in quad_keys: # region is small but incase stn is between 2 qkeys\n",
    "        # findn url\n",
    "        rows = ftp_links[ftp_links['QuadKey'] == qkey]\n",
    "        if rows.empty: return rows\n",
    "        url = rows.sort_values(by=\"Size\").iloc[0,:][\"Url\"] # choose url with highest info content        \n",
    "\n",
    "        df2 = pd.read_json(url,lines=True)\n",
    "        df2[\"geometry\"] = df2[\"geometry\"].apply(shapely.geometry.shape)\n",
    "\n",
    "        gdf = gpd.GeoDataFrame(df2, crs=4326)  \n",
    "            \n",
    "        # use spatial index to find building footprints in our area of interest.\n",
    "        sindex = gdf.sindex\n",
    "        bbox = aoi_shape.bounds\n",
    "        possible_matches_index = list(sindex.intersection(bbox))\n",
    "        possible_matches = gdf.iloc[possible_matches_index]\n",
    "        precise_matches = possible_matches[possible_matches.intersects(aoi_shape)]\n",
    "        # sort out buildings from final matches that don't have height\n",
    "        keep = precise_matches.apply(lambda row: row[\"properties\"] != {\"height\": -1.0}, axis=1)\n",
    "        ret = ret.append(precise_matches[keep])\n",
    "    return ret\n",
    "#footprints = get_footprints([23012311], coord_window(34.0522,-118.2437))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1a8c3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_osm_features (poly):\n",
    "    PLT = False\n",
    "    tmp = poly.bounds\n",
    "    NSEW = (tmp[3], tmp[1], tmp[2], tmp[0])\n",
    "    \n",
    "    def get_tags (tags): \n",
    "        try:\n",
    "            gdf = ox.features_from_bbox(*NSEW,tags=tags)\n",
    "            key = list(tags.keys())[0]\n",
    "            gdf = gdf.loc[\"way\",:][[key, \"geometry\"]]\n",
    "            gdf = gdf.rename(columns={key: \"feature\"})\n",
    "            return gdf\n",
    "        except Exception as e:\n",
    "            return None\n",
    "    \n",
    "    # get infastrucutre\n",
    "    ## roads\n",
    "    #G = ox.graph_from_bbox(*NSEW,network_type=\"drive_service\")\n",
    "    #gdf_roads = ox.graph_to_gdfs(G, nodes=False)\n",
    "    #buffer_size = 0.00005  # This is in degrees, adjust as needed\n",
    "    #gdf_roads['geometry'] = gdf_roads['geometry'].buffer(buffer_size)\n",
    "    \n",
    "    \n",
    "    ## landuse\n",
    "    landuse_foi = [\"residential\", \"industrial\", \"commercial\", \"greenfield\", \"brownfield\", \"grass\", \"forest\", \"farm\", \n",
    "                  \"orchard\", \"vineyard\"]\n",
    "    gdf_landuse = get_tags({\"landuse\": landuse_foi})\n",
    "\n",
    "    # water\n",
    "    water_foi = [\"river\", \"canal\", \"stream\", \"drain\"]\n",
    "    gdf_water = get_tags({\"waterway\": water_foi})\n",
    "    \n",
    "    # get natural features of interest\n",
    "    nat_foi = ['water', 'wood', 'grassland', 'heath', 'scrub', 'wetland', 'bare_rock']\n",
    "    gdf_nat = get_tags({'natural': nat_foi})\n",
    "    \n",
    "    # get highways\n",
    "    #road_foi = [\"motorway\", \"trunk\", \"primary\", \"secondary\", \"tertiary\", \"residential\"]\n",
    "    road_foi = [\"road\"]\n",
    "    gdf_road = get_tags({\"highway\": road_foi})\n",
    "\n",
    "    #map_plot(gdf_buildings['geometry'],clr=\"green\")\n",
    "    if PLT:\n",
    "        multi_map_plot(\n",
    "            ['red',\"blue\",\"green\",\"black\"],\n",
    "            bound_dots(coord_window(34.0522,-118.2437)),\n",
    "            gdf_nat,\n",
    "            gdf_parks,\n",
    "            gdf_landuse\n",
    "        )\n",
    "    return {\"landuse\": gdf_landuse, \"water\": gdf_water, \"natural\": gdf_nat, \"highway\": gdf_road},{\"landuse\": landuse_foi, \"water\": water_foi, \"natural\": nat_foi, \"highway\": road_foi}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a98ac7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bbox_from_tl (fn,easting,northing):\n",
    "    with rasterio.open(fn) as src:\n",
    "        shp = src.read(1).shape\n",
    "\n",
    "    tl = (easting, northing)\n",
    "    br = (easting+shp[1]*10,northing-shp[0]*10)\n",
    "\n",
    "    top_left_lat, top_left_lon = utm_to_latlon(*tl)\n",
    "    bottom_right_lat, bottom_right_lon = utm_to_latlon(*br)\n",
    "    \n",
    "    # Create Polygon\n",
    "    polygon = Polygon([\n",
    "        (top_left_lon, top_left_lat),  # Top-left\n",
    "        (top_left_lon, bottom_right_lat),  # Top-right\n",
    "        (bottom_right_lon, bottom_right_lat),  # Bottom-right\n",
    "        (bottom_right_lon, top_left_lat)  # Bottom-left\n",
    "    ])\n",
    "    \n",
    "    return polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c739acda",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rasterio' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [12], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m easting, northing \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m542685\u001b[39m,\u001b[38;5;241m4187515\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m####### file dependent stuff\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m e \u001b[38;5;241m=\u001b[39m \u001b[43mextract_subgrids_with_bounds_utm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m(\u001b[49m\u001b[43measting\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnorthing\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(e, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSubgrid\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBounds\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      8\u001b[0m grid_bbox \u001b[38;5;241m=\u001b[39m get_bbox_from_tl(filepath,easting,northing)\n",
      "Cell \u001b[0;32mIn [3], line 31\u001b[0m, in \u001b[0;36mextract_subgrids_with_bounds_utm\u001b[0;34m(raster_filepath, origin, pixel_size_m, subgrid_size, null_value, tol, zone_number, zone_letter)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_subgrids_with_bounds_utm\u001b[39m(raster_filepath, origin, pixel_size_m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, subgrid_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, null_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3.4e+38\u001b[39m, tol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-6\u001b[39m, zone_number\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m33\u001b[39m, zone_letter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mT\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 31\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mrasterio\u001b[49m\u001b[38;5;241m.\u001b[39mopen(raster_filepath) \u001b[38;5;28;01mas\u001b[39;00m src:\n\u001b[1;32m     32\u001b[0m         raster \u001b[38;5;241m=\u001b[39m src\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     34\u001b[0m     subgrids_with_bounds \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rasterio' is not defined"
     ]
    }
   ],
   "source": [
    "filepath = './heatmaps/sf/rasters_d1/am_t_f.tif'\n",
    "easting, northing = 542685,4187515\n",
    "\n",
    "####### file dependent stuff\n",
    "\n",
    "e = extract_subgrids_with_bounds_utm(filepath,(easting,northing))\n",
    "df = pd.DataFrame(e, columns=['Subgrid', 'Bounds'])\n",
    "grid_bbox = get_bbox_from_tl(filepath,easting,northing)\n",
    "\n",
    "# add col to df\n",
    "df[\"height_grid\"] = np.empty(df.shape[0],dtype=object)\n",
    "df[\"num_ftrs\"] = np.empty(df.shape[0],dtype=object)\n",
    "df[\"num_heights\"] = np.empty(df.shape[0],dtype=object)\n",
    "\n",
    "# get quadkeys that are in our aoi\n",
    "minx, miny, maxx, maxy = grid_bbox.bounds\n",
    "quad_keys = set()\n",
    "for tile in list(mercantile.tiles(minx, miny, maxx, maxy, zooms=9)):\n",
    "    quad_keys.add(int(mercantile.quadkey(tile)))\n",
    "quad_keys = list(quad_keys)\n",
    "\n",
    "to_drop = []\n",
    "\n",
    "############# SUBGRID DEPENDENT STUFF\n",
    "for curr_subgrid in tqdm(list(df.index)):\n",
    "    vertices_poly = df.iloc[curr_subgrid,:]['Bounds'] # subgrid Polygon\n",
    "    minx, miny, maxx, maxy = vertices_poly.bounds # reset bounds to the current subgrid\n",
    "\n",
    "    # query ms inside that window to check if there is building data (WITH HEIGHT) \n",
    "    footprints = get_footprints(quad_keys,vertices_poly)\n",
    "    # not avail: drop,next.\n",
    "    if footprints.empty: to_drop.append(curr_subgrid)\n",
    "\n",
    "    ##### GET FEATURES BASE\n",
    "    features, feature_tags = get_osm_features(vertices_poly)\n",
    "\n",
    "    ##### CREATE GRID WITH BOUNDS\n",
    "    res = 64\n",
    "    grid = np.empty((res,res),dtype=object)\n",
    "    # make res x res amount of boxes (+1 for edge)\n",
    "    bounds_x = np.linspace(minx,maxx,num=res+1)\n",
    "    bounds_y = np.linspace(maxy,miny,num=res+1) #### CHANGE MAXy-MINy\n",
    "\n",
    "    for x_i, xleft in enumerate(bounds_x[:-1]):\n",
    "        xright = bounds_x[x_i+1]\n",
    "        for y_i, yup in enumerate(bounds_y[:-1]):\n",
    "            ydown = bounds_y[y_i+1]\n",
    "            poly = shapely.geometry.box(xleft,ydown,xright,yup)\n",
    "            grid[y_i][x_i] = poly\n",
    "\n",
    "\n",
    "    # for each poly in grid, get height of building (or 0 for street)\n",
    "    heights_grid = np.zeros((res,res))\n",
    "    feature_grids = {}\n",
    "    feature_arrs = {}\n",
    "    num_heights = 0\n",
    "    num_ftrs = {}\n",
    "\n",
    "    for ftype in features.keys():\n",
    "        tag_key = feature_tags[ftype]\n",
    "        feature_grids[ftype] = np.array([[np.zeros(len(tag_key)) for _ in range(res)] for _ in range(res)])\n",
    "        feature_arrs[ftype] = [\"none\"] * res\n",
    "        num_ftrs[ftype] = 0\n",
    "\n",
    "\n",
    "    for y,row in enumerate(grid):\n",
    "        for x, square in enumerate(row):\n",
    "            ##### RASTERIZE BUILDING HEIGHTS\n",
    "            precise_matches = sindex_search (square,footprints)\n",
    "            if precise_matches.shape[0] == 0: \n",
    "                heights_grid[y][x] = 0\n",
    "            else:\n",
    "                heights_grid[y][x] = max(pd.json_normalize(precise_matches['properties'])['height'])\n",
    "                num_heights += 1\n",
    "\n",
    "            ##### RASTERIZE FEATURES\n",
    "            for ftype in features.keys():\n",
    "                tag_key = feature_tags[ftype]\n",
    "                ftr_df = features[ftype]\n",
    "                try:\n",
    "                    precise_matches = sindex_search (square,ftr_df)\n",
    "                except: \n",
    "                    continue\n",
    "                onehot = np.zeros(len(tag_key))\n",
    "                if precise_matches.shape[0] == 0:\n",
    "                    feature_grids[ftype][y][x] = onehot\n",
    "                    feature_arrs[ftype].append(\"none\")\n",
    "                    continue\n",
    "\n",
    "                ftr = precise_matches.iloc[0,:]['feature'] # residential, commercial, river...\n",
    "                onehot[tag_key.index(ftr)] = 1\n",
    "                feature_grids[ftype][y][x] = onehot\n",
    "                feature_arrs[ftype].append(ftr)\n",
    "                num_ftrs[ftype] += 1\n",
    "    df.loc[curr_subgrid,\"feature_grids\"] = [feature_grids]\n",
    "    df.at[curr_subgrid,\"height_grid\"] = heights_grid\n",
    "    df.at[curr_subgrid,\"num_ftrs\"] = num_ftrs\n",
    "    df.at[curr_subgrid,\"num_heights\"] = num_heights\n",
    "\n",
    "df = df.drop(pd.Index(to_drop))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7674eb8d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mto_pickle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./sf_am.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.to_pickle(\"./sf_am.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "056b831b",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './sf_am.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m am, af, pm \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./sf_am.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m, pd\u001b[38;5;241m.\u001b[39mread_pickle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./sf.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m), pd\u001b[38;5;241m.\u001b[39mread_pickle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./sf_pm.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/io/pickle.py:187\u001b[0m, in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;124;03mLoad pickled pandas object (or any object) from file.\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;124;03m4    4    9\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[1;32m    186\u001b[0m excs_to_catch \u001b[38;5;241m=\u001b[39m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m, \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m)\n\u001b[0;32m--> 187\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    194\u001b[0m \n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# 1) try standard library Pickle\u001b[39;00m\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;66;03m# 2) try pickle_compat (older pandas version) to handle subclass changes\u001b[39;00m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;66;03m# 3) try pickle_compat with latin-1 encoding upon a UnicodeDecodeError\u001b[39;00m\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    200\u001b[0m         \u001b[38;5;66;03m# TypeError for Cython complaints about object.__new__ vs Tick.__new__\u001b[39;00m\n\u001b[1;32m    201\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/io/common.py:795\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    786\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    787\u001b[0m             handle,\n\u001b[1;32m    788\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    791\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    792\u001b[0m         )\n\u001b[1;32m    793\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    794\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 795\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    796\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    798\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './sf_am.pkl'"
     ]
    }
   ],
   "source": [
    "am, af, pm = pd.read_pickle('./sf_am.pkl'), pd.read_pickle('./sf.pkl'), pd.read_pickle('./sf_pm.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ae87c71",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'am' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m am[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAMafPM\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[43mam\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])];af[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAMafPM\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(af\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])];pm[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAMafPM\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(pm\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'am' is not defined"
     ]
    }
   ],
   "source": [
    "am['AMafPM'] = [[1, 0, 0] for i in range(am.shape[0])];af['AMafPM'] = [[0, 1, 0] for i in range(af.shape[0])];pm['AMafPM'] = [[0, 0, 1] for i in range(pm.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "630e6bd3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m final_df \u001b[38;5;241m=\u001b[39m \u001b[43mpm\u001b[49m\u001b[38;5;241m.\u001b[39mappend(am\u001b[38;5;241m.\u001b[39mappend(af,ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pm' is not defined"
     ]
    }
   ],
   "source": [
    "final_df = pm.append(am.append(af,ignore_index=True),ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e65bc93",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfinal_df\u001b[49m\u001b[38;5;241m.\u001b[39mto_pickle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./final.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'final_df' is not defined"
     ]
    }
   ],
   "source": [
    "final_df.to_pickle(\"./final.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77e6e9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TESTING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e58dcb64",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m row \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m,:]\n\u001b[1;32m      2\u001b[0m res\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m\n\u001b[1;32m      3\u001b[0m minx, miny, maxx, maxy \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBounds\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mbounds\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "row = df.iloc[0,:]\n",
    "res=64\n",
    "minx, miny, maxx, maxy = row['Bounds'].bounds\n",
    "grid = np.empty((res,res),dtype=object)\n",
    "# make res x res amount of boxes (+1 for edge)\n",
    "bounds_x = np.linspace(minx,maxx,num=res+1)\n",
    "bounds_y = np.linspace(maxy,miny,num=res+1)\n",
    "\n",
    "for x_i, xleft in enumerate(bounds_x[:-1]):\n",
    "    xright = bounds_x[x_i+1]\n",
    "    for y_i, yup in enumerate(bounds_y[:-1]):\n",
    "        ydown = bounds_y[y_i+1]\n",
    "        poly = shapely.geometry.box(xleft,ydown,xright,yup)\n",
    "        grid[y_i][x_i] = poly\n",
    "\n",
    "ax = multi_map_plot(['black', 'red', 'blue'],gpd.GeoSeries(row['Bounds']),*grid)\n",
    "#annotate_gs(ax,grid,pool(64,row['height_grid']).flatten(),round_=True,grid=True,fontsize=3)\n",
    "annotate_gs(ax,grid,row['height_grid'].flatten(),round_=True,grid=True,fontsize=4)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819e2681",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
